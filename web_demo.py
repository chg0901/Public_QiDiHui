import json
import os
import time
import warnings

import appbuilder
import gradio as gr
import modelscope_studio as mgr

from rag_full.rag_langchain import FaissSearch, tokenize_chinese  # tokenize_chineseéœ€è¦åœ¨è¿™é‡Œimportï¼Œå¦åˆ™pickleä¼šæŠ¥é”™

warnings.filterwarnings('ignore')

# é…ç½®å¯†é’¥ä¸åº”ç”¨ID
# è®¾ç½®ç¯å¢ƒå˜é‡APPBUILDER_TOKENï¼Œç›®å‰å¡«çš„è¿™ä¸ªæ˜¯å®˜æ–¹çš„å—é™è¯•ç”¨TOKEN
os.environ["APPBUILDER_TOKEN"] = "bce-v3/ALTAK-DyYuSA9DVtgt3uLCJvj09/66566c4c39901e34c20829d07bbe993654c03452"
app_id = "b2c236c9-e544-4d16-8e74-016c602ef342"

# åˆ›å»ºä¸€ä¸ªFaissSearchå®ä¾‹ï¼Œç”¨äºæ£€ç´¢å‘é‡æ•°æ®åº“ï¼Œæ¯æ¬¡æ£€ç´¢è¿”å›top_kä¸ªç›¸å…³æ–‡æ¡£
search_engine = FaissSearch(path='./faiss_index_llama_full_ernie', top_k=5, threshold=10)

# ä½¿ç”¨appbuilderåˆ›å»ºLLMå¯¹è¯æ¥å£
llm = appbuilder.AppBuilderClient(app_id)

prompt = """
æ£€ç´¢ç»“æœ:
ç¬¬1ä¸ªæ®µè½:
{doc}
æ£€ç´¢è¯­å¥: ä½ çš„åå­—æ˜¯å¯è¿ªç»˜ï¼Œæ“…é•¿æŠŠç§‘å­¦äº‹å®ç¼–æˆæœ‰è¶£æ˜“æ‡‚çš„æ•…äº‹ï¼Œä»¥æ¿€å‘å„¿ç«¥å¯¹ç›¸å…³é¢†åŸŸçš„å¥½å¥‡å¿ƒï¼ŒåŒæ—¶è¿™ä¸ªæ•…äº‹åº”å½“ä½œä¸ºæˆä¸ºäº²å­å…±è¯»çš„æ¡¥æ¢ï¼ŒåŠ©åŠ›å­©å­ä»¬åœ¨è½»æ¾æ„‰å¿«çš„æ°›å›´ä¸­å­¦ä¹ æˆé•¿ã€‚
ä½ éœ€è¦æ ¹æ®æˆ‘çš„é—®é¢˜å’Œä½ æ‰€çŸ¥é“çš„çŸ¥è¯†ä¸ºæˆ‘åˆ›ä½œç¬¦åˆä»¥ä¸Šè¦æ±‚çš„æ•…äº‹ã€‚
æˆ‘çš„é—®é¢˜æ˜¯ï¼š
{query}
è¯·æ ¹æ®ä»¥ä¸Šæ£€ç´¢ç»“æœå›ç­”æ£€ç´¢è¯­å¥çš„é—®é¢˜
"""
docs = []


def resolve_assets(relative_path):
    return os.path.join(os.path.dirname(__file__), "resources",
                        relative_path)


conversation = [
    [None, {
        "text": "ä½ å¥½ï¼Œæ¬¢è¿æ¥åˆ°ğŸ˜¶â€ğŸŒ«ï¸æ™ºæ…§å¯è¿ªç»˜ï¼",
        "flushing": False
    }],
]


def get_last_bot_message(chatbot):
    return chatbot[-1][1]


def create_video_bot_message(text: str):
    return {
        "text": text,
    }


def create_image_bot_message(text: str):
    return {
        "text": text,
    }


async def chat_bot_with_llm(_input: mgr.MultimodalInput, _chatbot):
    global prompt, docs, search_engine, llm
    _chatbot.append([_input, [""]])
    yield gr.update(interactive=False, value=None), _chatbot

    docs = search_engine.search(_input.text)

    if len(docs) > 0:
        # å–å‡ºæ£€ç´¢åˆ°çš„ç›¸å…³æ€§æœ€é«˜çš„æ–‡æ¡£
        doc = docs[0]['content']
    else:
        # å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ï¼Œåˆ™å°†docç½®ä¸ºç©ºå­—ç¬¦ä¸²
        doc = ""

    final_prompt = prompt.replace('{query}', _input.text).replace('{doc}', doc)

    conversation_id = llm.create_conversation()
    messages = llm.run(conversation_id, final_prompt, stream=True)

    for content in messages.content:
        if content.answer is not None:
            _chatbot[-1][1][0] += content.answer
            yield {
                chat_bot_1: _chatbot,
            }


async def chat_bot_with_llm_image(_input: mgr.MultimodalInput, _chatbot):
    global prompt, docs, search_engine, llm
    _chatbot.append([_input, [""]])
    yield gr.update(interactive=False, value=None), _chatbot

    docs = search_engine.search(_input.text)

    if len(docs) > 0:
        # å–å‡ºæ£€ç´¢åˆ°çš„ç›¸å…³æ€§æœ€é«˜çš„æ–‡æ¡£
        doc = docs[0]['content']
        # å–å‡ºå›¾ç‰‡ä¿¡æ¯
        image_paths = docs[0]['image']
    else:
        # å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ï¼Œåˆ™å°†docç½®ä¸ºç©ºå­—ç¬¦ä¸²
        doc = ""
        # å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ï¼Œåˆ™å°†image_pathsç½®ä¸ºç©ºåˆ—è¡¨
        image_paths = []

    final_prompt = prompt.replace('{query}', _input.text).replace('{doc}', doc)

    conversation_id = llm.create_conversation()
    messages = llm.run(conversation_id, final_prompt, stream=True)

    for content in messages.content:
        if content.answer is not None:
            _chatbot[-1][1][0] += content.answer
            yield {
                chat_bot_2: _chatbot,
            }


    for path_dict in image_paths:
        image_path = './data/data269367/OEBPS/' + path_dict['path']
        _chatbot[-1][1][0] += f"""
<div style="text-align:center">
    <img style="width: 100%; border-radius: 0.32em;
    box-shadow: 0 2px 5px 0 rgba(35,36,38,.12),0 2px 10px 0 rgba(35,36,38,.08);" 
    src="{image_path}">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d7;
    display: inline-block;
    color: #999;
    padding: 2px;">{path_dict['tushuo']}</div>
</div>
"""
        yield {
            chat_bot_2: _chatbot,
        }


def chat_image(_input, _chatbot):
    _chatbot.append([_input, None])
    yield gr.update(interactive=False, value=None), _chatbot
    _chatbot[-1][1] = [
        create_image_bot_message("")
    ]

    time.sleep(1)
    get_last_bot_message(_chatbot)[0][
        "text"] = """ä½ å¥½ï¼Œæ¬¢è¿æ¥åˆ°ğŸ˜¶â€ğŸŒ«ï¸æ™ºæ…§å¯è¿ªç»˜ \n
        <accordion title="ç”Ÿæˆå›¾ç‰‡">

        ![IMAGEGEN]("https://oss.lingkongstudy.com.cn/blog/202405261707489.jpg")

        </accordion>"""
    yield {
        chat_bot_2: _chatbot,
    }


def chat_video(_input, _chatbot):
    _chatbot.append([_input, None])
    yield gr.update(interactive=False, value=None), _chatbot
    _chatbot[-1][1] = [
        create_video_bot_message("")
    ]

    time.sleep(1)
    get_last_bot_message(_chatbot)[0][
        "text"] = f"""ä½ å¥½ï¼Œæ¬¢è¿æ¥åˆ°ğŸ˜¶â€ğŸŒ«ï¸æ™ºæ…§å¯è¿ªç»˜ \n
        <video src="{resolve_assets("dog.mp4")}"></video> \n
        <accordion title="ç”Ÿæˆå›¾ç‰‡">

        <img src="https://oss.lingkongstudy.com.cn/blog/202405261707489.jpg" style="float: left;">
        <img src="https://oss.lingkongstudy.com.cn/blog/202405261707489.jpg" style="float: left;">

        </accordion>"""
    yield {
        chat_bot_3: _chatbot,
    }


def flushed():
    return gr.update(interactive=True)


def read_grouped_queries(file_path):
    # è¯»å– JSON æ–‡ä»¶
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # æå–å¹¶è¿”å› "grouped_queries" åˆ—è¡¨
    grouped_queries = data.get('grouped_queries', [])

    # è¿”å›ç¬¬ä¸€ä¸ªå­åˆ—è¡¨ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›ç©ºåˆ—è¡¨
    if grouped_queries:
        return grouped_queries
    else:
        return []


css = """
h1 {
  text-align: center;
  display: block;
}
"""
json_path = "list.json"

avatar_images = [
    # resolve_assets('user.jpeg'),
    # default bot avatar and name
    [{
        "name": "Curious baby",
        "avatar": "https://oss.lingkongstudy.com.cn/blog/202405271251981.png"
    }],

    [{
        "name": "QiDiHui",
        "avatar": "https://oss.lingkongstudy.com.cn/blog/202405261707489.jpg"
    }],

]

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(gr.themes.Soft(), css=css) as demo:
    html_code = """
            <h1 style="text-align: center;">ğŸ˜¶â€ğŸŒ«ï¸ æ™ºæ…§å¯è¿ªç»˜</h1>

            <p align="center">
                <img src="https://oss.lingkongstudy.com.cn/blog/202405261707489.jpg" alt="Logo" width="20%" style="border-radius: 5px;">
            </p>
            <div class="hint" style="text-align: center; background-color: rgba(255, 255, 0, 0.15); padding: 20px; margin: 20px; border-radius: 5px; border: 1px solid #ffcc00;">
                <h3 align="center">æ™ºæ…§å¯è¿ªç»˜å±•ç¤ºäº†è¯­è¨€ä¸æ™ºèƒ½æŠ€æœ¯çš„æ·±åº¦èåˆï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·å¸¦æ¥å…¨æ–°çš„äº’åŠ¨ä½“éªŒã€‚</h3>
            </div>

        """
    gr.Markdown(html_code)
    with gr.Tabs():
        with gr.TabItem("å¯¹è¯"):
            chat_bot_1 = mgr.Chatbot(
                value=conversation,
                avatar_image_width=60,
                avatar_images=avatar_images,
                height=500,
                flushing_speed=6,
            )
            state = gr.State([])

            input = mgr.MultimodalInput()
            input.submit(fn=chat_bot_with_llm, inputs=[input, chat_bot_1], outputs=[input, chat_bot_1])
            chat_bot_1.flushed(fn=flushed, outputs=[input])

            with gr.Column():
                with gr.Accordion(open=True, label="ğŸ˜€è¾“å…¥ç¤ºä¾‹ï¼š"):  # ä½¿ç”¨ Accordion ç»„ä»¶åˆ›å»ºå¯ä»¥æŠ˜å çš„åŒºåŸŸ
                    gr.Examples(examples=read_grouped_queries(json_path), inputs=input, outputs=chat_bot_1)

        with gr.TabItem("æ–‡ç”Ÿå›¾"):
            chat_bot_2 = mgr.Chatbot(
                value=conversation,
                avatar_image_width=40,
                avatar_images=avatar_images,
                height=500,
                flushing_speed=6,
            )

            input = mgr.MultimodalInput()
            input.submit(fn=chat_bot_with_llm_image, inputs=[input, chat_bot_2], outputs=[input, chat_bot_2])
            chat_bot_2.flushed(fn=flushed, outputs=[input])

            with gr.Column():
                with gr.Accordion(open=True, label="ğŸ˜€è¾“å…¥ç¤ºä¾‹ï¼š"):  # ä½¿ç”¨ Accordion ç»„ä»¶åˆ›å»ºå¯ä»¥æŠ˜å çš„åŒºåŸŸ
                    gr.Examples(examples=read_grouped_queries(json_path), inputs=input, outputs=chat_bot_2)

        with gr.TabItem("æ–‡ç”Ÿè§†é¢‘"):
            chat_bot_3 = mgr.Chatbot(
                value=conversation,
                avatar_image_width=40,
                avatar_images=avatar_images,
                height=500,
                flushing_speed=6,
            )

            input = mgr.MultimodalInput()
            input.submit(fn=chat_video, inputs=[input, chat_bot_3], outputs=[input, chat_bot_3])
            chat_bot_3.flushed(fn=flushed, outputs=[input])

            with gr.Column():
                with gr.Accordion(open=True, label="ğŸ˜€è¾“å…¥ç¤ºä¾‹ï¼š"):  # ä½¿ç”¨ Accordion ç»„ä»¶åˆ›å»ºå¯ä»¥æŠ˜å çš„åŒºåŸŸ
                    gr.Examples(examples=read_grouped_queries(json_path), inputs=input, outputs=chat_bot_3)

# å¯åŠ¨Gradioåº”ç”¨
if __name__ == "__main__":
    demo.queue().launch()
